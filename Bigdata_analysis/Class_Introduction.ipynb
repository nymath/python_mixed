{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2137b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:10:44.548075Z",
     "start_time": "2022-06-16T14:10:44.543071Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0d63c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:13:51.275153Z",
     "start_time": "2022-06-16T14:13:51.268233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9, 8, 6],\n",
       "        [8, 9, 7],\n",
       "        [6, 7, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matrix([[1,2,2],[2,1,1],[2,2,1]])\n",
    "X.transpose().dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "497eee63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:17:11.753193Z",
     "start_time": "2022-06-16T14:17:11.747193Z"
    }
   },
   "outputs": [],
   "source": [
    "class OlsRegressor:\n",
    "    # Class Variable\n",
    "    name = 'Mutiple Linear Regression'\n",
    "    \n",
    "    # The init method or constructor\n",
    "    def __init__(self, X,Y,solver):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.solver = solver\n",
    "        self.coef = (X.transpose()*X)**(-1)*(X.transpose()*Y)\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        return X_test*self.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb3b771d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:24:23.812990Z",
     "start_time": "2022-06-16T14:24:23.804990Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.matrix([[1,2],[1,1],[1,2],[1,3],[1,5],[1,2],[1,4],[1,10],[1,3]])\n",
    "Y = X[:,1]*2+np.matrix(np.random.randn(len(X))).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "813aa7f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:24:40.389901Z",
     "start_time": "2022-06-16T14:24:40.379900Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = OlsRegressor(X,Y,'OLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0cd514c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:24:45.217231Z",
     "start_time": "2022-06-16T14:24:45.204017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.35464123],\n",
       "        [ 1.9520034 ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22645528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:25:25.585144Z",
     "start_time": "2022-06-16T14:25:25.578223Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "236674bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:25:45.504093Z",
     "start_time": "2022-06-16T14:25:45.498096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.54936556],\n",
       "        [ 1.59736217],\n",
       "        [ 3.54936556],\n",
       "        [ 5.50136896],\n",
       "        [ 9.40537575],\n",
       "        [ 3.54936556],\n",
       "        [ 7.45337236],\n",
       "        [19.16539274],\n",
       "        [ 5.50136896]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac550d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab1f9194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:58:52.814572Z",
     "start_time": "2022-06-16T14:58:52.787592Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (Temp/ipykernel_23536/2908430064.py, line 151)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\17800\\AppData\\Local\\Temp/ipykernel_23536/2908430064.py\"\u001b[1;36m, line \u001b[1;32m151\u001b[0m\n\u001b[1;33m    return self\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(LinearClassifierMixin,SparseCoefMixin,BaseEstimator):\n",
    "        def __init__(self, penalty='l2', *, dual=False, tol=1e-4, C=1.0,\n",
    "                 fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "                 random_state=None, solver='lbfgs', max_iter=100,\n",
    "                 multi_class='auto', verbose=0, warm_start=False, n_jobs=None,\n",
    "                 l1_ratio=None):\n",
    "            self.penalty = penalty\n",
    "            self.dual = dual\n",
    "            self.tol = tol\n",
    "            self.C = C\n",
    "            self.fit_intercept = fit_intercept\n",
    "            self.intercept_scaling = intercept_scaling\n",
    "            self.class_weight = class_weight\n",
    "            self.random_state = random_state\n",
    "            self.solver = solver\n",
    "            self.max_iter = max_iter\n",
    "            self.multi_class = multi_class\n",
    "            self.verbose = verbose\n",
    "            self.warm_start = warm_start\n",
    "            self.n_jobs = n_jobs\n",
    "            self.l1_ratio = l1_ratio\n",
    "            \n",
    "        def fit(self, X, y, sample_weight=None):    \n",
    "            solver = _check_solver(self.solver, self.penalty, self.dual)\n",
    "            ## 报错信息\n",
    "            if not isinstance(self.C, numbers.Number) or self.C < 0:\n",
    "                raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
    "                                 % self.C)\n",
    "            if self.penalty == 'elasticnet':\n",
    "                if (not isinstance(self.l1_ratio, numbers.Number) or\n",
    "                        self.l1_ratio < 0 or self.l1_ratio > 1):\n",
    "                    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
    "                                     \" got (l1_ratio=%r)\" % self.l1_ratio)\n",
    "            elif self.l1_ratio is not None:\n",
    "                warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
    "                              \"'elasticnet'. Got \"\n",
    "                              \"(penalty={})\".format(self.penalty))\n",
    "            if self.penalty == 'none':\n",
    "                if self.C != 1.0:  # default values\n",
    "                    warnings.warn(\n",
    "                        \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
    "                        \"parameters\"\n",
    "                    )\n",
    "                    # Note that check for l1_ratio is done right above\n",
    "                C_ = np.inf\n",
    "                penalty = 'l2'\n",
    "            else:\n",
    "                C_ = self.C\n",
    "                penalty = self.penalty\n",
    "            if not isinstance(self.max_iter, numbers.Number) or self.max_iter < 0:\n",
    "                raise ValueError(\"Maximum number of iteration must be positive;\"\n",
    "                                 \" got (max_iter=%r)\" % self.max_iter)\n",
    "            if not isinstance(self.tol, numbers.Number) or self.tol < 0:\n",
    "                raise ValueError(\"Tolerance for stopping criteria must be \"\n",
    "                                 \"positive; got (tol=%r)\" % self.tol)\n",
    "\n",
    "            if solver == 'lbfgs':\n",
    "                _dtype = np.float64\n",
    "            else:\n",
    "                _dtype = [np.float64, np.float32]\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n",
    "                                   order=\"C\",\n",
    "                                   accept_large_sparse=solver != 'liblinear')\n",
    "        check_classification_targets(y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        multi_class = _check_multi_class(self.multi_class, solver,\n",
    "                                         len(self.classes_))\n",
    "#                 if solver == 'liblinear':\n",
    "#                     if effective_n_jobs(self.n_jobs) != 1:\n",
    "#                         warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
    "#                                       \" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\n",
    "#                                       \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
    "#                     self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
    "#                         X, y, self.C, self.fit_intercept, self.intercept_scaling,\n",
    "#                         self.class_weight, self.penalty, self.dual, self.verbose,\n",
    "#                         self.max_iter, self.tol, self.random_state,\n",
    "#                         sample_weight=sample_weight)\n",
    "#                     self.n_iter_ = np.array([n_iter_])\n",
    "#                     return self\n",
    "\n",
    "        if solver in ['sag', 'saga']:\n",
    "            max_squared_sum = row_norms(X, squared=True).max()\n",
    "        else:\n",
    "            max_squared_sum = None\n",
    "\n",
    "        n_classes = len(self.classes_)\n",
    "        classes_ = self.classes_\n",
    "        if n_classes < 2:\n",
    "            raise ValueError(\"This solver needs samples of at least 2 classes\"\n",
    "                             \" in the data, but the data contains only one\"\n",
    "                             \" class: %r\" % classes_[0])\n",
    "\n",
    "        if len(self.classes_) == 2:\n",
    "            n_classes = 1\n",
    "            classes_ = classes_[1:]\n",
    "\n",
    "        if self.warm_start:\n",
    "            warm_start_coef = getattr(self, 'coef_', None)\n",
    "        else:\n",
    "            warm_start_coef = None\n",
    "        if warm_start_coef is not None and self.fit_intercept:\n",
    "            warm_start_coef = np.append(warm_start_coef,\n",
    "                                        self.intercept_[:, np.newaxis],\n",
    "                                        axis=1)\n",
    "\n",
    "        # Hack so that we iterate only once for the multinomial case.\n",
    "        if multi_class == 'multinomial':\n",
    "            classes_ = [None]\n",
    "            warm_start_coef = [warm_start_coef]\n",
    "        if warm_start_coef is None:\n",
    "            warm_start_coef = [None] * n_classes\n",
    "\n",
    "        path_func = delayed(_logistic_regression_path)\n",
    "\n",
    "        # The SAG solver releases the GIL so it's more efficient to use\n",
    "        # threads for this solver.\n",
    "        if solver in ['sag', 'saga']:\n",
    "            prefer = 'threads'\n",
    "        else:\n",
    "            prefer = 'processes'\n",
    "        fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "                               **_joblib_parallel_args(prefer=prefer))(\n",
    "            path_func(X, y, pos_class=class_, Cs=[C_],\n",
    "                      l1_ratio=self.l1_ratio, fit_intercept=self.fit_intercept,\n",
    "                      tol=self.tol, verbose=self.verbose, solver=solver,\n",
    "                      multi_class=multi_class, max_iter=self.max_iter,\n",
    "                      class_weight=self.class_weight, check_input=False,\n",
    "                      random_state=self.random_state, coef=warm_start_coef_,\n",
    "                      penalty=penalty, max_squared_sum=max_squared_sum,\n",
    "                      sample_weight=sample_weight)\n",
    "            for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
    "\n",
    "        fold_coefs_, _, n_iter_ = zip(*fold_coefs_)\n",
    "        self.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, 0]\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if multi_class == 'multinomial':\n",
    "            self.coef_ = fold_coefs_[0][0]\n",
    "        else:\n",
    "            self.coef_ = np.asarray(fold_coefs_)\n",
    "            self.coef_ = self.coef_.reshape(n_classes, n_features +\n",
    "                                            int(self.fit_intercept))\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = self.coef_[:, -1]\n",
    "            self.coef_ = self.coef_[:, :-1]\n",
    "        else:\n",
    "            self.intercept_ = np.zeros(n_classes)\n",
    "        return self\n",
    "    \n",
    "        def predict_proba(self, X):\n",
    "            check_is_fitted(self)\n",
    "\n",
    "        ovr = (self.multi_class in [\"ovr\", \"warn\"] or\n",
    "               (self.multi_class == 'auto' and (self.classes_.size <= 2 or\n",
    "                                                self.solver == 'liblinear')))\n",
    "        if ovr:\n",
    "            return super()._predict_proba_lr(X)\n",
    "        else:\n",
    "            decision = self.decision_function(X)\n",
    "            if decision.ndim == 1:\n",
    "                # Workaround for multi_class=\"multinomial\" and binary outcomes\n",
    "                # which requires softmax prediction with only a 1D decision.\n",
    "                decision_2d = np.c_[-decision, decision]\n",
    "            else:\n",
    "                decision_2d = decision\n",
    "            return softmax(decision_2d, copy=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28d7a758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T15:01:59.307359Z",
     "start_time": "2022-06-16T15:01:59.285415Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_deprecate_positional_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23536/2384152910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     def __init__(self, *, fit_intercept=True, normalize=False, copy_X=True,\n\u001b[0;32m      4\u001b[0m                  n_jobs=None, positive=False):\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23536/2384152910.py\u001b[0m in \u001b[0;36mLinearRegression\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     def __init__(self, *, fit_intercept=True, normalize=False, copy_X=True,\n\u001b[0;32m      4\u001b[0m                  n_jobs=None, positive=False):\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_deprecate_positional_args' is not defined"
     ]
    }
   ],
   "source": [
    "class LinearRegression(MultiOutputMixin, RegressorMixin, LinearModel):\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, *, fit_intercept=True, normalize=False, copy_X=True,\n",
    "                 n_jobs=None, positive=False):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "        self.positive = positive\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "\n",
    "        n_jobs_ = self.n_jobs\n",
    "\n",
    "        accept_sparse = False if self.positive else ['csr', 'csc', 'coo']\n",
    "\n",
    "        X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n",
    "                                   y_numeric=True, multi_output=True)\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = _check_sample_weight(sample_weight, X,\n",
    "                                                 dtype=X.dtype)\n",
    "\n",
    "        X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n",
    "            X, y, fit_intercept=self.fit_intercept, normalize=self.normalize,\n",
    "            copy=self.copy_X, sample_weight=sample_weight,\n",
    "            return_mean=True)\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            # Sample weight can be implemented via a simple rescaling.\n",
    "            X, y = _rescale_data(X, y, sample_weight)\n",
    "\n",
    "        if self.positive:\n",
    "            if y.ndim < 2:\n",
    "                self.coef_, self._residues = optimize.nnls(X, y)\n",
    "            else:\n",
    "                # scipy.optimize.nnls cannot handle y with shape (M, K)\n",
    "                outs = Parallel(n_jobs=n_jobs_)(\n",
    "                        delayed(optimize.nnls)(X, y[:, j])\n",
    "                        for j in range(y.shape[1]))\n",
    "                self.coef_, self._residues = map(np.vstack, zip(*outs))\n",
    "        elif sp.issparse(X):\n",
    "            X_offset_scale = X_offset / X_scale\n",
    "\n",
    "            def matvec(b):\n",
    "                return X.dot(b) - b.dot(X_offset_scale)\n",
    "\n",
    "            def rmatvec(b):\n",
    "                return X.T.dot(b) - X_offset_scale * np.sum(b)\n",
    "\n",
    "            X_centered = sparse.linalg.LinearOperator(shape=X.shape,\n",
    "                                                      matvec=matvec,\n",
    "                                                      rmatvec=rmatvec)\n",
    "\n",
    "            if y.ndim < 2:\n",
    "                out = sparse_lsqr(X_centered, y)\n",
    "                self.coef_ = out[0]\n",
    "                self._residues = out[3]\n",
    "            else:\n",
    "                # sparse_lstsq cannot handle y with shape (M, K)\n",
    "                outs = Parallel(n_jobs=n_jobs_)(\n",
    "                    delayed(sparse_lsqr)(X_centered, y[:, j].ravel())\n",
    "                    for j in range(y.shape[1]))\n",
    "                self.coef_ = np.vstack([out[0] for out in outs])\n",
    "                self._residues = np.vstack([out[3] for out in outs])\n",
    "        else:\n",
    "            self.coef_, self._residues, self.rank_, self.singular_ = \\\n",
    "                linalg.lstsq(X, y)\n",
    "            self.coef_ = self.coef_.T\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            self.coef_ = np.ravel(self.coef_)\n",
    "        self._set_intercept(X_offset, y_offset, X_scale)\n",
    "        return self    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3591b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T15:01:08.757943Z",
     "start_time": "2022-06-16T15:01:08.274783Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_CV(Xdata,Ydata,class_model,size_pct=0.2,model=\"Temp\",rn=0,i=1):\n",
    "    globals()['Model_{}_{}'.format(model,i)] = class_model()\n",
    "    globals()['X_train_{}_{}'.format(model,i)],globals()['X_test_{}_{}'.format(model,i)],globals()['Y_train_{}_{}'.format(model,i)],globals()['Y_test_{}_{}'.format(model,i)] = train_test_split(Xdata, Ydata, test_size=size_pct, random_state=rn)\n",
    "    globals()['X_trainabs_{}_{}'.format(model,i)],globals()['X_valid_{}_{}'.format(model,i)],globals()['Y_trainabs_{}_{}'.format(model,i)],globals()['Y_valid_{}_{}'.format(model,i)] =train_test_split(globals()['X_train_{}_{}'.format(model,i)],globals()['Y_train_{}_{}'.format(model,i)],test_size=size_pct,random_state=rn)\n",
    "    globals()['Model_{}_{}'.format(model,i)].fit(globals()['X_train_{}_{}'.format(model,i)],globals()['Y_train_{}_{}'.format(model,i)])\n",
    "    #在train上预测\n",
    "    globals()['Y_train_predict_CV_{}_{}'.format(model,i)] = cross_val_predict(globals()['Model_{}_{}'.format(model,i)],globals()['X_train_{}_{}'.format(model,i)],globals()['Y_train_{}_{}'.format(model,i)],cv=5)\n",
    "    # 在test集合上预测---------------------------------------------------------------------------------\n",
    "    globals()['Y_test_predict_CV_{}_{}'.format(model,i)] = cross_val_predict(globals()['Model_{}_{}'.format(model,i)],globals()['X_test_{}_{}'.format(model,i)],globals()['Y_test_{}_{}'.format(model,i)],cv=5)\n",
    "    # 得到AUC ---------------------------------------------------------------------------------------\n",
    "    globals()['Y_test_prob_CV_{}_{}'.format(model,i)] = cross_val_predict(globals()['Model_{}_{}'.format(model,i)],globals()['X_test_{}_{}'.format(model,i)],globals()['Y_test_{}_{}'.format(model,i)],cv=5,method='predict_proba')\n",
    "    globals()['fpr_CV_{}_{}'.format(model,i)], globals()['tpr_CV_{}_{}'.format(model,i)], globals()['thresholds_CV_{}_{}'.format(model,i)] = roc_curve(globals()['Y_test_{}_{}'.format(model,i)], (globals()['Y_test_prob_CV_{}_{}'.format(model,i)])[:, 1])\n",
    "    globals()['auc_CV_{}_{}'.format(model,i)] = auc(globals()['fpr_CV_{}_{}'.format(model,i)], globals()['tpr_CV_{}_{}'.format(model,i)])\n",
    "    return globals()['auc_CV_{}_{}'.format(model,i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix (training):\\n {0}\\n\".format(confusion_matrix(globals()['{}_Y_train_{}'.format(model,i)], globals()['{}_Y_train_predict_{}'.format(model,i)])))\n",
    "print(\"Classification report (training):\\n {0}\".format(classification_report(globals()['{}_Y_train_{}'.format(model,i)], globals()['{}_Y_train_predict_{}'.format(model,i)])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
